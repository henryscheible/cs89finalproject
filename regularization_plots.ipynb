{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compress import main\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from compress import main\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../nunits_exp/results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30513/2571968182.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../nunits_exp/results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nunits\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnunits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../nunits_exp/results.csv'"
     ]
    }
   ],
   "source": [
    "models_df = pd.read_csv(\"../nunits_exp/results.csv\")\n",
    "models_df = models_df.loc[models_df[\"nunits\"] <= 256]\n",
    "nunits=256\n",
    "data_aug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrt_256 = json.load(open(\"./figures/Rank_Reduced_Training_nunits=256_dataaug=False.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30513/1344682438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nunits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrrt_256\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rank_constraints\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrrt_256\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Accuracies Vs Rank: Hidden Units={nunits}, Data Augmentation={bool(data_aug)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rank'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(models_df[\"nunits\"], models_df[\"val_acc\"], color='blue', s=50)\n",
    "plt.scatter(rrt_256[\"rank_constraints\"], rrt_256[\"val_accs\"], color=\"red\", s=50)\n",
    "plt.title(f'Test Accuracies Vs Rank: Hidden Units={nunits}, Data Augmentation={bool(data_aug)}')\n",
    "plt.xlabel('Rank')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"./figures/Rank_constraint_vs_small_model_256.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>datadir</th>\n",
       "      <th>nchannels</th>\n",
       "      <th>nclasses</th>\n",
       "      <th>nunits</th>\n",
       "      <th>...</th>\n",
       "      <th>l2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nlayers</th>\n",
       "      <th>rank_constraint</th>\n",
       "      <th>data_aug</th>\n",
       "      <th>device</th>\n",
       "      <th>train_dataset_path</th>\n",
       "      <th>val_dataset_path</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67780</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64138</td>\n",
       "      <td>1.024430</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>1.310140</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_2.pt</td>\n",
       "      <td>80.405609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.997742</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>1.349168</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_3.pt</td>\n",
       "      <td>80.241499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.58462</td>\n",
       "      <td>1.204006</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>1.332390</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_4.pt</td>\n",
       "      <td>80.291114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.52604</td>\n",
       "      <td>1.362426</td>\n",
       "      <td>0.5053</td>\n",
       "      <td>1.419070</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_5.pt</td>\n",
       "      <td>80.291972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24920</td>\n",
       "      <td>1.960396</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>1.958487</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_6.pt</td>\n",
       "      <td>79.625279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.23364</td>\n",
       "      <td>2.061307</td>\n",
       "      <td>0.2369</td>\n",
       "      <td>2.059770</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_7.pt</td>\n",
       "      <td>79.332326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.18662</td>\n",
       "      <td>2.137762</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>2.137904</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_8.pt</td>\n",
       "      <td>79.176732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.99218</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>3.695829</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_9.pt</td>\n",
       "      <td>81.474658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75560</td>\n",
       "      <td>0.719939</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>1.278123</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_10.pt</td>\n",
       "      <td>128.116338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.76384</td>\n",
       "      <td>0.703675</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>1.278120</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_11.pt</td>\n",
       "      <td>128.783373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.67132</td>\n",
       "      <td>0.963105</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>1.327274</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_12.pt</td>\n",
       "      <td>129.036036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.63248</td>\n",
       "      <td>1.079457</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>1.289076</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_13.pt</td>\n",
       "      <td>128.917446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.57400</td>\n",
       "      <td>1.235691</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>1.344021</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_14.pt</td>\n",
       "      <td>128.789963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.25012</td>\n",
       "      <td>1.956291</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>1.954840</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_15.pt</td>\n",
       "      <td>128.391636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.24868</td>\n",
       "      <td>1.960181</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>1.958615</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_16.pt</td>\n",
       "      <td>128.365170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.23546</td>\n",
       "      <td>2.062271</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>2.061459</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_17.pt</td>\n",
       "      <td>127.627961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  model_id  train_acc  train_loss  val_acc  val_loss   datadir  \\\n",
       "0            0         0    0.67780    0.925592   0.5368  1.422607  datasets   \n",
       "1            1         1    0.74796    0.731219   0.5570  1.295658  datasets   \n",
       "2            2         2    0.64138    1.024430   0.5337  1.310140  datasets   \n",
       "3            3         3    0.65566    0.997742   0.5386  1.349168  datasets   \n",
       "4            4         4    0.58462    1.204006   0.5350  1.332390  datasets   \n",
       "5            5         5    0.52604    1.362426   0.5053  1.419070  datasets   \n",
       "6            6         6    0.24920    1.960396   0.2517  1.958487  datasets   \n",
       "7            7         7    0.23364    2.061307   0.2369  2.059770  datasets   \n",
       "8            8         8    0.18662    2.137762   0.1851  2.137904  datasets   \n",
       "9            9         9    0.99218    0.024848   0.5641  3.695829  datasets   \n",
       "10          10        10    0.75560    0.719939   0.5692  1.278123  datasets   \n",
       "11          11        11    0.76384    0.703675   0.5585  1.278120  datasets   \n",
       "12          12        12    0.67132    0.963105   0.5422  1.327274  datasets   \n",
       "13          13        13    0.63248    1.079457   0.5528  1.289076  datasets   \n",
       "14          14        14    0.57400    1.235691   0.5343  1.344021  datasets   \n",
       "15          15        15    0.25012    1.956291   0.2517  1.954840  datasets   \n",
       "16          16        16    0.24868    1.960181   0.2512  1.958615  datasets   \n",
       "17          17        17    0.23546    2.062271   0.2360  2.061459  datasets   \n",
       "\n",
       "    nchannels  nclasses  nunits  ...    l2  dropout  nlayers  rank_constraint  \\\n",
       "0           3        10     256  ...  0.00     0.00        3                0   \n",
       "1           3        10     256  ...  0.00     0.25        3                0   \n",
       "2           3        10     256  ...  0.00     0.50        3                0   \n",
       "3           3        10     256  ...  0.01     0.00        3                0   \n",
       "4           3        10     256  ...  0.01     0.25        3                0   \n",
       "5           3        10     256  ...  0.01     0.50        3                0   \n",
       "6           3        10     256  ...  0.10     0.00        3                0   \n",
       "7           3        10     256  ...  0.10     0.25        3                0   \n",
       "8           3        10     256  ...  0.10     0.50        3                0   \n",
       "9           3        10    1024  ...  0.00     0.00        3                0   \n",
       "10          3        10    1024  ...  0.00     0.25        3                0   \n",
       "11          3        10    1024  ...  0.00     0.50        3                0   \n",
       "12          3        10    1024  ...  0.01     0.00        3                0   \n",
       "13          3        10    1024  ...  0.01     0.25        3                0   \n",
       "14          3        10    1024  ...  0.01     0.50        3                0   \n",
       "15          3        10    1024  ...  0.10     0.00        3                0   \n",
       "16          3        10    1024  ...  0.10     0.25        3                0   \n",
       "17          3        10    1024  ...  0.10     0.50        3                0   \n",
       "\n",
       "    data_aug  device            train_dataset_path  \\\n",
       "0          0    cuda  ./processed_train_dataset.pt   \n",
       "1          0    cuda  ./processed_train_dataset.pt   \n",
       "2          0    cuda  ./processed_train_dataset.pt   \n",
       "3          0    cuda  ./processed_train_dataset.pt   \n",
       "4          0    cuda  ./processed_train_dataset.pt   \n",
       "5          0    cuda  ./processed_train_dataset.pt   \n",
       "6          0    cuda  ./processed_train_dataset.pt   \n",
       "7          0    cuda  ./processed_train_dataset.pt   \n",
       "8          0    cuda  ./processed_train_dataset.pt   \n",
       "9          0    cuda  ./processed_train_dataset.pt   \n",
       "10         0    cuda  ./processed_train_dataset.pt   \n",
       "11         0    cuda  ./processed_train_dataset.pt   \n",
       "12         0    cuda  ./processed_train_dataset.pt   \n",
       "13         0    cuda  ./processed_train_dataset.pt   \n",
       "14         0    cuda  ./processed_train_dataset.pt   \n",
       "15         0    cuda  ./processed_train_dataset.pt   \n",
       "16         0    cuda  ./processed_train_dataset.pt   \n",
       "17         0    cuda  ./processed_train_dataset.pt   \n",
       "\n",
       "              val_dataset_path               checkpoint_path  training_time  \n",
       "0   ./processed_val_dataset.pt   ./batched_models/model_0.pt      79.768554  \n",
       "1   ./processed_val_dataset.pt   ./batched_models/model_1.pt      80.393442  \n",
       "2   ./processed_val_dataset.pt   ./batched_models/model_2.pt      80.405609  \n",
       "3   ./processed_val_dataset.pt   ./batched_models/model_3.pt      80.241499  \n",
       "4   ./processed_val_dataset.pt   ./batched_models/model_4.pt      80.291114  \n",
       "5   ./processed_val_dataset.pt   ./batched_models/model_5.pt      80.291972  \n",
       "6   ./processed_val_dataset.pt   ./batched_models/model_6.pt      79.625279  \n",
       "7   ./processed_val_dataset.pt   ./batched_models/model_7.pt      79.332326  \n",
       "8   ./processed_val_dataset.pt   ./batched_models/model_8.pt      79.176732  \n",
       "9   ./processed_val_dataset.pt   ./batched_models/model_9.pt      81.474658  \n",
       "10  ./processed_val_dataset.pt  ./batched_models/model_10.pt     128.116338  \n",
       "11  ./processed_val_dataset.pt  ./batched_models/model_11.pt     128.783373  \n",
       "12  ./processed_val_dataset.pt  ./batched_models/model_12.pt     129.036036  \n",
       "13  ./processed_val_dataset.pt  ./batched_models/model_13.pt     128.917446  \n",
       "14  ./processed_val_dataset.pt  ./batched_models/model_14.pt     128.789963  \n",
       "15  ./processed_val_dataset.pt  ./batched_models/model_15.pt     128.391636  \n",
       "16  ./processed_val_dataset.pt  ./batched_models/model_16.pt     128.365170  \n",
       "17  ./processed_val_dataset.pt  ./batched_models/model_17.pt     127.627961  \n",
       "\n",
       "[18 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_models_df = pd.read_csv(\"./results.csv\")\n",
    "reg_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "reg_models_df[\"rank\"] = [0] * len(reg_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9b12c82b5441dab2caae7d961ef53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 1\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1-Rank Approximation @ Inference===================\n",
      " Training loss: 2.785   Validation loss 2.783    Training accuracy: 0.114   Validation accuracy: 0.113\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 6\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 6-Rank Approximation @ Inference===================\n",
      " Training loss: 2.563   Validation loss 2.594    Training accuracy: 0.227   Validation accuracy: 0.224\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 11\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 11-Rank Approximation @ Inference===================\n",
      " Training loss: 2.116   Validation loss 2.194    Training accuracy: 0.339   Validation accuracy: 0.326\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 16\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 16-Rank Approximation @ Inference===================\n",
      " Training loss: 1.953   Validation loss 2.061    Training accuracy: 0.389   Validation accuracy: 0.372\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 20\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 20-Rank Approximation @ Inference===================\n",
      " Training loss: 1.804   Validation loss 1.918    Training accuracy: 0.434   Validation accuracy: 0.409\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 30\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 30-Rank Approximation @ Inference===================\n",
      " Training loss: 1.537   Validation loss 1.710    Training accuracy: 0.503   Validation accuracy: 0.463\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 40\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 40-Rank Approximation @ Inference===================\n",
      " Training loss: 1.409   Validation loss 1.644    Training accuracy: 0.535   Validation accuracy: 0.484\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 50\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 50-Rank Approximation @ Inference===================\n",
      " Training loss: 1.287   Validation loss 1.564    Training accuracy: 0.567   Validation accuracy: 0.495\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 60\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 60-Rank Approximation @ Inference===================\n",
      " Training loss: 1.201   Validation loss 1.516    Training accuracy: 0.590   Validation accuracy: 0.513\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 70\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 70-Rank Approximation @ Inference===================\n",
      " Training loss: 1.160   Validation loss 1.500    Training accuracy: 0.601   Validation accuracy: 0.517\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 80\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 80-Rank Approximation @ Inference===================\n",
      " Training loss: 1.123   Validation loss 1.488    Training accuracy: 0.612   Validation accuracy: 0.517\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 90\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 90-Rank Approximation @ Inference===================\n",
      " Training loss: 1.096   Validation loss 1.478    Training accuracy: 0.619   Validation accuracy: 0.519\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 100\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 100-Rank Approximation @ Inference===================\n",
      " Training loss: 1.075   Validation loss 1.472    Training accuracy: 0.626   Validation accuracy: 0.522\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 150\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 150-Rank Approximation @ Inference===================\n",
      " Training loss: 0.992   Validation loss 1.446    Training accuracy: 0.656   Validation accuracy: 0.531\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 200\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 200-Rank Approximation @ Inference===================\n",
      " Training loss: 0.948   Validation loss 1.430    Training accuracy: 0.671   Validation accuracy: 0.537\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 256 and reconstructed rank 250\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 250-Rank Approximation @ Inference===================\n",
      " Training loss: 0.926   Validation loss 1.423    Training accuracy: 0.678   Validation accuracy: 0.537\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Compressing Model 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a18d2d94423485d98df949df6f7d388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 1\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1-Rank Approximation @ Inference===================\n",
      " Training loss: 3.943   Validation loss 3.950    Training accuracy: 0.105   Validation accuracy: 0.105\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 6\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 6-Rank Approximation @ Inference===================\n",
      " Training loss: 3.327   Validation loss 3.448    Training accuracy: 0.258   Validation accuracy: 0.246\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 11\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 11-Rank Approximation @ Inference===================\n",
      " Training loss: 2.210   Validation loss 2.372    Training accuracy: 0.394   Validation accuracy: 0.362\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 16\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 16-Rank Approximation @ Inference===================\n",
      " Training loss: 1.855   Validation loss 2.037    Training accuracy: 0.437   Validation accuracy: 0.404\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 20\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 20-Rank Approximation @ Inference===================\n",
      " Training loss: 1.624   Validation loss 1.838    Training accuracy: 0.484   Validation accuracy: 0.439\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 30\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 30-Rank Approximation @ Inference===================\n",
      " Training loss: 1.407   Validation loss 1.667    Training accuracy: 0.533   Validation accuracy: 0.477\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 40\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 40-Rank Approximation @ Inference===================\n",
      " Training loss: 1.243   Validation loss 1.556    Training accuracy: 0.573   Validation accuracy: 0.500\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 50\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 50-Rank Approximation @ Inference===================\n",
      " Training loss: 1.128   Validation loss 1.490    Training accuracy: 0.603   Validation accuracy: 0.513\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 60\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 60-Rank Approximation @ Inference===================\n",
      " Training loss: 1.050   Validation loss 1.444    Training accuracy: 0.627   Validation accuracy: 0.526\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 70\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 70-Rank Approximation @ Inference===================\n",
      " Training loss: 0.985   Validation loss 1.407    Training accuracy: 0.648   Validation accuracy: 0.532\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 80\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 80-Rank Approximation @ Inference===================\n",
      " Training loss: 0.939   Validation loss 1.384    Training accuracy: 0.664   Validation accuracy: 0.539\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 90\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 90-Rank Approximation @ Inference===================\n",
      " Training loss: 0.900   Validation loss 1.366    Training accuracy: 0.679   Validation accuracy: 0.542\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 100\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 100-Rank Approximation @ Inference===================\n",
      " Training loss: 0.863   Validation loss 1.348    Training accuracy: 0.691   Validation accuracy: 0.547\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 150\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 150-Rank Approximation @ Inference===================\n",
      " Training loss: 0.776   Validation loss 1.310    Training accuracy: 0.727   Validation accuracy: 0.551\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 200\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 200-Rank Approximation @ Inference===================\n",
      " Training loss: 0.741   Validation loss 1.300    Training accuracy: 0.744   Validation accuracy: 0.555\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 256 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 255 and reconstructed rank 250\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 250-Rank Approximation @ Inference===================\n",
      " Training loss: 0.733   Validation loss 1.296    Training accuracy: 0.748   Validation accuracy: 0.559\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Compressing Model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a5c2852e4d428ea29f6d5bfbbd5410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 1\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1-Rank Approximation @ Inference===================\n",
      " Training loss: 2.423   Validation loss 2.422    Training accuracy: 0.108   Validation accuracy: 0.107\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 6\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 6-Rank Approximation @ Inference===================\n",
      " Training loss: 2.106   Validation loss 2.123    Training accuracy: 0.240   Validation accuracy: 0.231\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 11\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 11-Rank Approximation @ Inference===================\n",
      " Training loss: 2.056   Validation loss 2.105    Training accuracy: 0.305   Validation accuracy: 0.289\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 16\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 16-Rank Approximation @ Inference===================\n",
      " Training loss: 1.912   Validation loss 1.994    Training accuracy: 0.363   Validation accuracy: 0.340\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 20\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 20-Rank Approximation @ Inference===================\n",
      " Training loss: 1.857   Validation loss 1.967    Training accuracy: 0.403   Validation accuracy: 0.378\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 30\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 30-Rank Approximation @ Inference===================\n",
      " Training loss: 1.640   Validation loss 1.783    Training accuracy: 0.468   Validation accuracy: 0.434\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 40\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 40-Rank Approximation @ Inference===================\n",
      " Training loss: 1.472   Validation loss 1.658    Training accuracy: 0.508   Validation accuracy: 0.465\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 50\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 50-Rank Approximation @ Inference===================\n",
      " Training loss: 1.302   Validation loss 1.526    Training accuracy: 0.546   Validation accuracy: 0.488\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 60\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 60-Rank Approximation @ Inference===================\n",
      " Training loss: 1.190   Validation loss 1.438    Training accuracy: 0.586   Validation accuracy: 0.515\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 70\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 70-Rank Approximation @ Inference===================\n",
      " Training loss: 1.134   Validation loss 1.407    Training accuracy: 0.604   Validation accuracy: 0.525\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 80\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 80-Rank Approximation @ Inference===================\n",
      " Training loss: 1.107   Validation loss 1.391    Training accuracy: 0.612   Validation accuracy: 0.526\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 90\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 90-Rank Approximation @ Inference===================\n",
      " Training loss: 1.080   Validation loss 1.378    Training accuracy: 0.623   Validation accuracy: 0.529\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 100\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 100-Rank Approximation @ Inference===================\n",
      " Training loss: 1.057   Validation loss 1.369    Training accuracy: 0.631   Validation accuracy: 0.534\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 150\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 150-Rank Approximation @ Inference===================\n",
      " Training loss: 1.018   Validation loss 1.354    Training accuracy: 0.647   Validation accuracy: 0.537\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 200\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 200-Rank Approximation @ Inference===================\n",
      " Training loss: 1.003   Validation loss 1.350    Training accuracy: 0.653   Validation accuracy: 0.538\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 256 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 252 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 221 and reconstructed rank 221\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 250-Rank Approximation @ Inference===================\n",
      " Training loss: 0.998   Validation loss 1.349    Training accuracy: 0.655   Validation accuracy: 0.538\n",
      "\n",
      "Total Parameters for Truncated Model: 920842\n",
      "Compressing Model 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cf90d011ca4bedbf5b93ce259442f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 1\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1-Rank Approximation @ Inference===================\n",
      " Training loss: 5.710   Validation loss 5.704    Training accuracy: 0.104   Validation accuracy: 0.103\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 6\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 6-Rank Approximation @ Inference===================\n",
      " Training loss: 6.794   Validation loss 6.901    Training accuracy: 0.178   Validation accuracy: 0.174\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 11\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 11-Rank Approximation @ Inference===================\n",
      " Training loss: 8.297   Validation loss 8.489    Training accuracy: 0.264   Validation accuracy: 0.254\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 16\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 16-Rank Approximation @ Inference===================\n",
      " Training loss: 8.133   Validation loss 8.568    Training accuracy: 0.304   Validation accuracy: 0.285\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 20\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 20-Rank Approximation @ Inference===================\n",
      " Training loss: 8.280   Validation loss 8.946    Training accuracy: 0.337   Validation accuracy: 0.313\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 30\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 30-Rank Approximation @ Inference===================\n",
      " Training loss: 7.210   Validation loss 8.250    Training accuracy: 0.423   Validation accuracy: 0.383\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 40\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 40-Rank Approximation @ Inference===================\n",
      " Training loss: 6.045   Validation loss 7.509    Training accuracy: 0.477   Validation accuracy: 0.420\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 50\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 50-Rank Approximation @ Inference===================\n",
      " Training loss: 5.213   Validation loss 7.100    Training accuracy: 0.524   Validation accuracy: 0.447\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 60\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 60-Rank Approximation @ Inference===================\n",
      " Training loss: 4.473   Validation loss 6.766    Training accuracy: 0.560   Validation accuracy: 0.467\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 70\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 70-Rank Approximation @ Inference===================\n",
      " Training loss: 3.887   Validation loss 6.524    Training accuracy: 0.590   Validation accuracy: 0.477\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 80\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 80-Rank Approximation @ Inference===================\n",
      " Training loss: 3.015   Validation loss 5.987    Training accuracy: 0.638   Validation accuracy: 0.491\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 90\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 90-Rank Approximation @ Inference===================\n",
      " Training loss: 2.324   Validation loss 5.516    Training accuracy: 0.682   Validation accuracy: 0.508\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 100\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 100-Rank Approximation @ Inference===================\n",
      " Training loss: 1.874   Validation loss 5.244    Training accuracy: 0.719   Validation accuracy: 0.518\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 150\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 150-Rank Approximation @ Inference===================\n",
      " Training loss: 0.705   Validation loss 4.505    Training accuracy: 0.842   Validation accuracy: 0.546\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 200\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 200-Rank Approximation @ Inference===================\n",
      " Training loss: 0.302   Validation loss 4.151    Training accuracy: 0.914   Validation accuracy: 0.558\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 250\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 250-Rank Approximation @ Inference===================\n",
      " Training loss: 0.161   Validation loss 3.998    Training accuracy: 0.949   Validation accuracy: 0.558\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 300\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 300\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 300\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 300-Rank Approximation @ Inference===================\n",
      " Training loss: 0.105   Validation loss 3.920    Training accuracy: 0.966   Validation accuracy: 0.560\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 400\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 400\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 400\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 400-Rank Approximation @ Inference===================\n",
      " Training loss: 0.062   Validation loss 3.836    Training accuracy: 0.979   Validation accuracy: 0.562\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 500\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 500\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 500\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 500-Rank Approximation @ Inference===================\n",
      " Training loss: 0.045   Validation loss 3.780    Training accuracy: 0.985   Validation accuracy: 0.564\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 600\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 600\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 600\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 600-Rank Approximation @ Inference===================\n",
      " Training loss: 0.034   Validation loss 3.753    Training accuracy: 0.989   Validation accuracy: 0.565\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 700\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 700\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 700\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 700-Rank Approximation @ Inference===================\n",
      " Training loss: 0.030   Validation loss 3.727    Training accuracy: 0.990   Validation accuracy: 0.563\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 800\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 800\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 800\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 800-Rank Approximation @ Inference===================\n",
      " Training loss: 0.027   Validation loss 3.709    Training accuracy: 0.991   Validation accuracy: 0.564\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 900\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 900\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 900\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 900-Rank Approximation @ Inference===================\n",
      " Training loss: 0.026   Validation loss 3.701    Training accuracy: 0.992   Validation accuracy: 0.566\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 1000\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1024 and reconstructed rank 1000\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1023 and reconstructed rank 1000\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1000-Rank Approximation @ Inference===================\n",
      " Training loss: 0.025   Validation loss 3.700    Training accuracy: 0.992   Validation accuracy: 0.564\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Compressing Model 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652ea78f308049e399f940895b312213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 1\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1-Rank Approximation @ Inference===================\n",
      " Training loss: 3.639   Validation loss 3.623    Training accuracy: 0.101   Validation accuracy: 0.102\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 6\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 6-Rank Approximation @ Inference===================\n",
      " Training loss: 3.042   Validation loss 3.115    Training accuracy: 0.259   Validation accuracy: 0.252\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 11\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 11-Rank Approximation @ Inference===================\n",
      " Training loss: 2.222   Validation loss 2.356    Training accuracy: 0.366   Validation accuracy: 0.342\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 16\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 16-Rank Approximation @ Inference===================\n",
      " Training loss: 2.010   Validation loss 2.164    Training accuracy: 0.413   Validation accuracy: 0.388\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 20\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 20-Rank Approximation @ Inference===================\n",
      " Training loss: 1.908   Validation loss 2.086    Training accuracy: 0.433   Validation accuracy: 0.404\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 30\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 30-Rank Approximation @ Inference===================\n",
      " Training loss: 1.529   Validation loss 1.758    Training accuracy: 0.503   Validation accuracy: 0.465\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 40\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 40\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 40-Rank Approximation @ Inference===================\n",
      " Training loss: 1.320   Validation loss 1.591    Training accuracy: 0.550   Validation accuracy: 0.488\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 50\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 50\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 50-Rank Approximation @ Inference===================\n",
      " Training loss: 1.216   Validation loss 1.517    Training accuracy: 0.577   Validation accuracy: 0.507\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 60\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 60\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 60-Rank Approximation @ Inference===================\n",
      " Training loss: 1.108   Validation loss 1.442    Training accuracy: 0.606   Validation accuracy: 0.524\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 70\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 70\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 70-Rank Approximation @ Inference===================\n",
      " Training loss: 1.058   Validation loss 1.414    Training accuracy: 0.622   Validation accuracy: 0.528\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 80\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 80\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 80-Rank Approximation @ Inference===================\n",
      " Training loss: 1.021   Validation loss 1.388    Training accuracy: 0.634   Validation accuracy: 0.534\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 90\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 90\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 90-Rank Approximation @ Inference===================\n",
      " Training loss: 0.995   Validation loss 1.375    Training accuracy: 0.641   Validation accuracy: 0.538\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 100\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 100\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 100-Rank Approximation @ Inference===================\n",
      " Training loss: 0.974   Validation loss 1.363    Training accuracy: 0.650   Validation accuracy: 0.537\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 150\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 150\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 150-Rank Approximation @ Inference===================\n",
      " Training loss: 0.909   Validation loss 1.332    Training accuracy: 0.675   Validation accuracy: 0.547\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 200\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 200\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 200-Rank Approximation @ Inference===================\n",
      " Training loss: 0.870   Validation loss 1.322    Training accuracy: 0.691   Validation accuracy: 0.548\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 250\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 250\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 250-Rank Approximation @ Inference===================\n",
      " Training loss: 0.841   Validation loss 1.311    Training accuracy: 0.702   Validation accuracy: 0.552\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 300\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 300\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 300\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 300-Rank Approximation @ Inference===================\n",
      " Training loss: 0.816   Validation loss 1.303    Training accuracy: 0.711   Validation accuracy: 0.559\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 400\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 400\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 400\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 400-Rank Approximation @ Inference===================\n",
      " Training loss: 0.784   Validation loss 1.296    Training accuracy: 0.725   Validation accuracy: 0.559\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 500\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 500\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 500\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 500-Rank Approximation @ Inference===================\n",
      " Training loss: 0.759   Validation loss 1.289    Training accuracy: 0.737   Validation accuracy: 0.564\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 600\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 600\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 600\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 600-Rank Approximation @ Inference===================\n",
      " Training loss: 0.744   Validation loss 1.285    Training accuracy: 0.746   Validation accuracy: 0.567\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 700\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 700\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 700\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 700-Rank Approximation @ Inference===================\n",
      " Training loss: 0.734   Validation loss 1.283    Training accuracy: 0.749   Validation accuracy: 0.569\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 800\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 800\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 800\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 800-Rank Approximation @ Inference===================\n",
      " Training loss: 0.726   Validation loss 1.281    Training accuracy: 0.753   Validation accuracy: 0.571\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 900\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 900\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 900\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 900-Rank Approximation @ Inference===================\n",
      " Training loss: 0.722   Validation loss 1.279    Training accuracy: 0.755   Validation accuracy: 0.569\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 1000\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 1023 and reconstructed rank 1000\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 1024 and reconstructed rank 1000\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1000-Rank Approximation @ Inference===================\n",
      " Training loss: 0.720   Validation loss 1.278    Training accuracy: 0.756   Validation accuracy: 0.569\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Compressing Model 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d8138acfaf4039a8a6d5b9cc5cebda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 997 and reconstructed rank 1\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 962 and reconstructed rank 1\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 1-Rank Approximation @ Inference===================\n",
      " Training loss: 2.403   Validation loss 2.402    Training accuracy: 0.108   Validation accuracy: 0.112\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 997 and reconstructed rank 6\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 962 and reconstructed rank 6\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 6-Rank Approximation @ Inference===================\n",
      " Training loss: 2.135   Validation loss 2.150    Training accuracy: 0.229   Validation accuracy: 0.225\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 997 and reconstructed rank 11\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 962 and reconstructed rank 11\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 11-Rank Approximation @ Inference===================\n",
      " Training loss: 2.041   Validation loss 2.094    Training accuracy: 0.310   Validation accuracy: 0.301\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 997 and reconstructed rank 16\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 962 and reconstructed rank 16\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 16-Rank Approximation @ Inference===================\n",
      " Training loss: 1.912   Validation loss 1.991    Training accuracy: 0.380   Validation accuracy: 0.366\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 997 and reconstructed rank 20\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 962 and reconstructed rank 20\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 20-Rank Approximation @ Inference===================\n",
      " Training loss: 1.777   Validation loss 1.879    Training accuracy: 0.415   Validation accuracy: 0.398\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n",
      "Original rank 1024 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc2.weight\n",
      "Original rank 997 and reconstructed rank 30\n",
      "Applying truncated SVD on layer fc3.weight\n",
      "Original rank 962 and reconstructed rank 30\n",
      "Data augmentation on the train set: FALSE\n",
      "Files already downloaded and verified\n",
      "Data augmentation on the val set: FALSE\n",
      "Files already downloaded and verified\n",
      "=================== Summary for model Model with 30-Rank Approximation @ Inference===================\n",
      " Training loss: 1.556   Validation loss 1.698    Training accuracy: 0.486   Validation accuracy: 0.453\n",
      "\n",
      "Total Parameters for Truncated Model: 5256202\n",
      "Applying truncated SVD on layer fc1.weight\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m rank \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m, reg_models_df\u001b[39m.\u001b[39mloc[i][\u001b[39m\"\u001b[39m\u001b[39mnunits\u001b[39m\u001b[39m\"\u001b[39m])):\n\u001b[1;32m      7\u001b[0m     args \u001b[39m=\u001b[39m SimpleNamespace(checkpoint_path\u001b[39m=\u001b[39mreg_models_df\u001b[39m.\u001b[39mloc[i][\u001b[39m\"\u001b[39m\u001b[39mcheckpoint_path\u001b[39m\u001b[39m\"\u001b[39m], rank\u001b[39m=\u001b[39mrank)\n\u001b[0;32m----> 8\u001b[0m     val_acc \u001b[39m=\u001b[39m main(args)\n\u001b[1;32m      9\u001b[0m     reg_models_df\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(reg_models_df)] \u001b[39m=\u001b[39m reg_models_df\u001b[39m.\u001b[39mloc[i]\n\u001b[1;32m     10\u001b[0m     reg_models_df\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(reg_models_df) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m val_acc\n",
      "File \u001b[0;32m~/cs89finalproject/compress.py:79\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     75\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(weights)\n\u001b[1;32m     76\u001b[0m \u001b[39m# view_weights(weights)\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m _, val_acc, _, _ \u001b[39m=\u001b[39m eval_model(model, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mModel with \u001b[39;49m\u001b[39m{\u001b[39;49;00mk\u001b[39m}\u001b[39;49;00m\u001b[39m-Rank Approximation @ Inference\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     80\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal Parameters for Truncated Model: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msum\u001b[39m([p\u001b[39m.\u001b[39mnumel()\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mp\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mweights\u001b[39m.\u001b[39mvalues()])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[39m# model_B_file = torch.load(\"./models/nlayers=3_k=16.pt\", map_location=torch.device('cpu'))['model state']\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m# print(f\"Total Parameters for train rank-constrained Model: {sum([p.numel() for p in model_B_file.values()])}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/cs89finalproject/compress.py:48\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[1;32m     44\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 48\u001b[0m train_acc, train_loss \u001b[39m=\u001b[39m validate(model, device, train_loader, criterion)\n\u001b[1;32m     49\u001b[0m val_acc, val_loss \u001b[39m=\u001b[39m validate(model, device, val_loader, criterion)\n\u001b[1;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m=================== Summary for model \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m===================\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m     52\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m   Validation loss \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m   \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m   Validation accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/cs89finalproject/train.py:59\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, device, val_loader, criterion)\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mfor\u001b[39;49;00m data, target \u001b[39min\u001b[39;49;00m val_loader:\n\u001b[1;32m     60\u001b[0m         data, target \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mto(device)\u001b[39m.\u001b[39;49mview(data\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), target\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     61\u001b[0m         model\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1444\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1445\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/multiprocessing/connection.py:1135\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m   1134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m   1137\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/cs89finalproject/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in [0, 1, 3, 9, 10, 12]: \n",
    "    print(f\"Compressing Model {i}\")\n",
    "    for rank in tqdm(list(range(1, 20, 5)) + list(range(20, 100, 10)) + list(range(100, 256, 50)) + list(range(300, reg_models_df.loc[i][\"nunits\"], 100))):\n",
    "        args = SimpleNamespace(checkpoint_path=reg_models_df.loc[i][\"checkpoint_path\"], rank=rank)\n",
    "        val_acc = main(args)\n",
    "        reg_models_df.loc[len(reg_models_df)] = reg_models_df.loc[i]\n",
    "        reg_models_df.loc[len(reg_models_df) - 1, \"val_acc\"] = float(val_acc)\n",
    "        reg_models_df.loc[len(reg_models_df) - 1, \"rank\"] = float(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models_df = reg_models_df.loc[0:281]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>datadir</th>\n",
       "      <th>nchannels</th>\n",
       "      <th>nclasses</th>\n",
       "      <th>nunits</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nlayers</th>\n",
       "      <th>rank_constraint</th>\n",
       "      <th>data_aug</th>\n",
       "      <th>device</th>\n",
       "      <th>train_dataset_path</th>\n",
       "      <th>val_dataset_path</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>training_time</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67780</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64138</td>\n",
       "      <td>1.024430</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>1.310140</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_2.pt</td>\n",
       "      <td>80.405609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.997742</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>1.349168</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_3.pt</td>\n",
       "      <td>80.241499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.58462</td>\n",
       "      <td>1.204006</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>1.332390</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_4.pt</td>\n",
       "      <td>80.291114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.67132</td>\n",
       "      <td>0.963105</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>1.327274</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_12.pt</td>\n",
       "      <td>129.036036</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.67132</td>\n",
       "      <td>0.963105</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>1.327274</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_12.pt</td>\n",
       "      <td>129.036036</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.67132</td>\n",
       "      <td>0.963105</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>1.327274</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_12.pt</td>\n",
       "      <td>129.036036</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.67132</td>\n",
       "      <td>0.963105</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>1.327274</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_12.pt</td>\n",
       "      <td>129.036036</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.67132</td>\n",
       "      <td>0.963105</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>1.327274</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_12.pt</td>\n",
       "      <td>129.036036</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  model_id  train_acc  train_loss  val_acc  val_loss   datadir  \\\n",
       "0             0         0    0.67780    0.925592   0.5368  1.422607  datasets   \n",
       "1             1         1    0.74796    0.731219   0.5570  1.295658  datasets   \n",
       "2             2         2    0.64138    1.024430   0.5337  1.310140  datasets   \n",
       "3             3         3    0.65566    0.997742   0.5386  1.349168  datasets   \n",
       "4             4         4    0.58462    1.204006   0.5350  1.332390  datasets   \n",
       "..          ...       ...        ...         ...      ...       ...       ...   \n",
       "133          12        12    0.67132    0.963105   0.5426  1.327274  datasets   \n",
       "134          12        12    0.67132    0.963105   0.5424  1.327274  datasets   \n",
       "135          12        12    0.67132    0.963105   0.5422  1.327274  datasets   \n",
       "136          12        12    0.67132    0.963105   0.5423  1.327274  datasets   \n",
       "137          12        12    0.67132    0.963105   0.5424  1.327274  datasets   \n",
       "\n",
       "     nchannels  nclasses  nunits  ...  dropout  nlayers  rank_constraint  \\\n",
       "0            3        10     256  ...     0.00        3                0   \n",
       "1            3        10     256  ...     0.25        3                0   \n",
       "2            3        10     256  ...     0.50        3                0   \n",
       "3            3        10     256  ...     0.00        3                0   \n",
       "4            3        10     256  ...     0.25        3                0   \n",
       "..         ...       ...     ...  ...      ...      ...              ...   \n",
       "133          3        10    1024  ...     0.00        3                0   \n",
       "134          3        10    1024  ...     0.00        3                0   \n",
       "135          3        10    1024  ...     0.00        3                0   \n",
       "136          3        10    1024  ...     0.00        3                0   \n",
       "137          3        10    1024  ...     0.00        3                0   \n",
       "\n",
       "     data_aug  device            train_dataset_path  \\\n",
       "0           0    cuda  ./processed_train_dataset.pt   \n",
       "1           0    cuda  ./processed_train_dataset.pt   \n",
       "2           0    cuda  ./processed_train_dataset.pt   \n",
       "3           0    cuda  ./processed_train_dataset.pt   \n",
       "4           0    cuda  ./processed_train_dataset.pt   \n",
       "..        ...     ...                           ...   \n",
       "133         0    cuda  ./processed_train_dataset.pt   \n",
       "134         0    cuda  ./processed_train_dataset.pt   \n",
       "135         0    cuda  ./processed_train_dataset.pt   \n",
       "136         0    cuda  ./processed_train_dataset.pt   \n",
       "137         0    cuda  ./processed_train_dataset.pt   \n",
       "\n",
       "               val_dataset_path               checkpoint_path  training_time  \\\n",
       "0    ./processed_val_dataset.pt   ./batched_models/model_0.pt      79.768554   \n",
       "1    ./processed_val_dataset.pt   ./batched_models/model_1.pt      80.393442   \n",
       "2    ./processed_val_dataset.pt   ./batched_models/model_2.pt      80.405609   \n",
       "3    ./processed_val_dataset.pt   ./batched_models/model_3.pt      80.241499   \n",
       "4    ./processed_val_dataset.pt   ./batched_models/model_4.pt      80.291114   \n",
       "..                          ...                           ...            ...   \n",
       "133  ./processed_val_dataset.pt  ./batched_models/model_12.pt     129.036036   \n",
       "134  ./processed_val_dataset.pt  ./batched_models/model_12.pt     129.036036   \n",
       "135  ./processed_val_dataset.pt  ./batched_models/model_12.pt     129.036036   \n",
       "136  ./processed_val_dataset.pt  ./batched_models/model_12.pt     129.036036   \n",
       "137  ./processed_val_dataset.pt  ./batched_models/model_12.pt     129.036036   \n",
       "\n",
       "     rank  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "..    ...  \n",
       "133   600  \n",
       "134   700  \n",
       "135   800  \n",
       "136   900  \n",
       "137  1000  \n",
       "\n",
       "[138 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>datadir</th>\n",
       "      <th>nchannels</th>\n",
       "      <th>nclasses</th>\n",
       "      <th>nunits</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nlayers</th>\n",
       "      <th>rank_constraint</th>\n",
       "      <th>data_aug</th>\n",
       "      <th>device</th>\n",
       "      <th>train_dataset_path</th>\n",
       "      <th>val_dataset_path</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>training_time</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5219</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>1.422607</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_0.pt</td>\n",
       "      <td>79.768554</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  model_id  train_acc  train_loss  val_acc  val_loss   datadir  \\\n",
       "18           0         0     0.6778    0.925592   0.1129  1.422607  datasets   \n",
       "19           0         0     0.6778    0.925592   0.2241  1.422607  datasets   \n",
       "20           0         0     0.6778    0.925592   0.3257  1.422607  datasets   \n",
       "21           0         0     0.6778    0.925592   0.3721  1.422607  datasets   \n",
       "22           0         0     0.6778    0.925592   0.4091  1.422607  datasets   \n",
       "23           0         0     0.6778    0.925592   0.4632  1.422607  datasets   \n",
       "24           0         0     0.6778    0.925592   0.4840  1.422607  datasets   \n",
       "25           0         0     0.6778    0.925592   0.4946  1.422607  datasets   \n",
       "26           0         0     0.6778    0.925592   0.5129  1.422607  datasets   \n",
       "27           0         0     0.6778    0.925592   0.5168  1.422607  datasets   \n",
       "28           0         0     0.6778    0.925592   0.5167  1.422607  datasets   \n",
       "29           0         0     0.6778    0.925592   0.5192  1.422607  datasets   \n",
       "30           0         0     0.6778    0.925592   0.5219  1.422607  datasets   \n",
       "31           0         0     0.6778    0.925592   0.5306  1.422607  datasets   \n",
       "32           0         0     0.6778    0.925592   0.5366  1.422607  datasets   \n",
       "33           0         0     0.6778    0.925592   0.5369  1.422607  datasets   \n",
       "\n",
       "    nchannels  nclasses  nunits  ...  dropout  nlayers  rank_constraint  \\\n",
       "18          3        10     256  ...      0.0        3                0   \n",
       "19          3        10     256  ...      0.0        3                0   \n",
       "20          3        10     256  ...      0.0        3                0   \n",
       "21          3        10     256  ...      0.0        3                0   \n",
       "22          3        10     256  ...      0.0        3                0   \n",
       "23          3        10     256  ...      0.0        3                0   \n",
       "24          3        10     256  ...      0.0        3                0   \n",
       "25          3        10     256  ...      0.0        3                0   \n",
       "26          3        10     256  ...      0.0        3                0   \n",
       "27          3        10     256  ...      0.0        3                0   \n",
       "28          3        10     256  ...      0.0        3                0   \n",
       "29          3        10     256  ...      0.0        3                0   \n",
       "30          3        10     256  ...      0.0        3                0   \n",
       "31          3        10     256  ...      0.0        3                0   \n",
       "32          3        10     256  ...      0.0        3                0   \n",
       "33          3        10     256  ...      0.0        3                0   \n",
       "\n",
       "    data_aug  device            train_dataset_path  \\\n",
       "18         0    cuda  ./processed_train_dataset.pt   \n",
       "19         0    cuda  ./processed_train_dataset.pt   \n",
       "20         0    cuda  ./processed_train_dataset.pt   \n",
       "21         0    cuda  ./processed_train_dataset.pt   \n",
       "22         0    cuda  ./processed_train_dataset.pt   \n",
       "23         0    cuda  ./processed_train_dataset.pt   \n",
       "24         0    cuda  ./processed_train_dataset.pt   \n",
       "25         0    cuda  ./processed_train_dataset.pt   \n",
       "26         0    cuda  ./processed_train_dataset.pt   \n",
       "27         0    cuda  ./processed_train_dataset.pt   \n",
       "28         0    cuda  ./processed_train_dataset.pt   \n",
       "29         0    cuda  ./processed_train_dataset.pt   \n",
       "30         0    cuda  ./processed_train_dataset.pt   \n",
       "31         0    cuda  ./processed_train_dataset.pt   \n",
       "32         0    cuda  ./processed_train_dataset.pt   \n",
       "33         0    cuda  ./processed_train_dataset.pt   \n",
       "\n",
       "              val_dataset_path              checkpoint_path  training_time  \\\n",
       "18  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "19  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "20  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "21  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "22  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "23  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "24  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "25  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "26  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "27  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "28  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "29  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "30  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "31  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "32  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "33  ./processed_val_dataset.pt  ./batched_models/model_0.pt      79.768554   \n",
       "\n",
       "    rank  \n",
       "18     1  \n",
       "19     6  \n",
       "20    11  \n",
       "21    16  \n",
       "22    20  \n",
       "23    30  \n",
       "24    40  \n",
       "25    50  \n",
       "26    60  \n",
       "27    70  \n",
       "28    80  \n",
       "29    90  \n",
       "30   100  \n",
       "31   150  \n",
       "32   200  \n",
       "33   250  \n",
       "\n",
       "[16 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_256 = reg_models_df.loc[(reg_models_df[\"Unnamed: 0\"] == 0) & (reg_models_df[\"rank\"] != 0)]\n",
    "baseline_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>datadir</th>\n",
       "      <th>nchannels</th>\n",
       "      <th>nclasses</th>\n",
       "      <th>nunits</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nlayers</th>\n",
       "      <th>rank_constraint</th>\n",
       "      <th>data_aug</th>\n",
       "      <th>device</th>\n",
       "      <th>train_dataset_path</th>\n",
       "      <th>val_dataset_path</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>training_time</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.2459</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.4769</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5264</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5393</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5553</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74796</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.5593</td>\n",
       "      <td>1.295658</td>\n",
       "      <td>datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cuda</td>\n",
       "      <td>./processed_train_dataset.pt</td>\n",
       "      <td>./processed_val_dataset.pt</td>\n",
       "      <td>./batched_models/model_1.pt</td>\n",
       "      <td>80.393442</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  model_id  train_acc  train_loss  val_acc  val_loss   datadir  \\\n",
       "34           1         1    0.74796    0.731219   0.1053  1.295658  datasets   \n",
       "35           1         1    0.74796    0.731219   0.2459  1.295658  datasets   \n",
       "36           1         1    0.74796    0.731219   0.3624  1.295658  datasets   \n",
       "37           1         1    0.74796    0.731219   0.4037  1.295658  datasets   \n",
       "38           1         1    0.74796    0.731219   0.4389  1.295658  datasets   \n",
       "39           1         1    0.74796    0.731219   0.4769  1.295658  datasets   \n",
       "40           1         1    0.74796    0.731219   0.5003  1.295658  datasets   \n",
       "41           1         1    0.74796    0.731219   0.5132  1.295658  datasets   \n",
       "42           1         1    0.74796    0.731219   0.5264  1.295658  datasets   \n",
       "43           1         1    0.74796    0.731219   0.5321  1.295658  datasets   \n",
       "44           1         1    0.74796    0.731219   0.5393  1.295658  datasets   \n",
       "45           1         1    0.74796    0.731219   0.5417  1.295658  datasets   \n",
       "46           1         1    0.74796    0.731219   0.5466  1.295658  datasets   \n",
       "47           1         1    0.74796    0.731219   0.5506  1.295658  datasets   \n",
       "48           1         1    0.74796    0.731219   0.5553  1.295658  datasets   \n",
       "49           1         1    0.74796    0.731219   0.5593  1.295658  datasets   \n",
       "\n",
       "    nchannels  nclasses  nunits  ...  dropout  nlayers  rank_constraint  \\\n",
       "34          3        10     256  ...     0.25        3                0   \n",
       "35          3        10     256  ...     0.25        3                0   \n",
       "36          3        10     256  ...     0.25        3                0   \n",
       "37          3        10     256  ...     0.25        3                0   \n",
       "38          3        10     256  ...     0.25        3                0   \n",
       "39          3        10     256  ...     0.25        3                0   \n",
       "40          3        10     256  ...     0.25        3                0   \n",
       "41          3        10     256  ...     0.25        3                0   \n",
       "42          3        10     256  ...     0.25        3                0   \n",
       "43          3        10     256  ...     0.25        3                0   \n",
       "44          3        10     256  ...     0.25        3                0   \n",
       "45          3        10     256  ...     0.25        3                0   \n",
       "46          3        10     256  ...     0.25        3                0   \n",
       "47          3        10     256  ...     0.25        3                0   \n",
       "48          3        10     256  ...     0.25        3                0   \n",
       "49          3        10     256  ...     0.25        3                0   \n",
       "\n",
       "    data_aug  device            train_dataset_path  \\\n",
       "34         0    cuda  ./processed_train_dataset.pt   \n",
       "35         0    cuda  ./processed_train_dataset.pt   \n",
       "36         0    cuda  ./processed_train_dataset.pt   \n",
       "37         0    cuda  ./processed_train_dataset.pt   \n",
       "38         0    cuda  ./processed_train_dataset.pt   \n",
       "39         0    cuda  ./processed_train_dataset.pt   \n",
       "40         0    cuda  ./processed_train_dataset.pt   \n",
       "41         0    cuda  ./processed_train_dataset.pt   \n",
       "42         0    cuda  ./processed_train_dataset.pt   \n",
       "43         0    cuda  ./processed_train_dataset.pt   \n",
       "44         0    cuda  ./processed_train_dataset.pt   \n",
       "45         0    cuda  ./processed_train_dataset.pt   \n",
       "46         0    cuda  ./processed_train_dataset.pt   \n",
       "47         0    cuda  ./processed_train_dataset.pt   \n",
       "48         0    cuda  ./processed_train_dataset.pt   \n",
       "49         0    cuda  ./processed_train_dataset.pt   \n",
       "\n",
       "              val_dataset_path              checkpoint_path  training_time  \\\n",
       "34  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "35  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "36  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "37  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "38  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "39  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "40  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "41  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "42  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "43  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "44  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "45  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "46  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "47  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "48  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "49  ./processed_val_dataset.pt  ./batched_models/model_1.pt      80.393442   \n",
       "\n",
       "    rank  \n",
       "34     1  \n",
       "35     6  \n",
       "36    11  \n",
       "37    16  \n",
       "38    20  \n",
       "39    30  \n",
       "40    40  \n",
       "41    50  \n",
       "42    60  \n",
       "43    70  \n",
       "44    80  \n",
       "45    90  \n",
       "46   100  \n",
       "47   150  \n",
       "48   200  \n",
       "49   250  \n",
       "\n",
       "[16 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_256 = reg_models_df.loc[(reg_models_df[\"Unnamed: 0\"] == 1) & (reg_models_df[\"rank\"] != 0)]\n",
    "dropout_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(baseline_256[\"rank\"], baseline_256[\"val_acc\"], color='blue', s=50, label=\"No Regularization\")\n",
    "plt.scatter(dropout_256[\"rank\"], dropout_256[\"val_acc\"], color=\"red\", s=50, label=\"Dropout, p=0.25\")\n",
    "plt.title(f\"Dropout's Effect on Truncated Accuracy, nunits=256\")\n",
    "plt.xlabel('Rank')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"./figures/Dropout_256.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_256 = reg_models_df.loc[(reg_models_df[\"Unnamed: 0\"] == 3) & (reg_models_df[\"rank\"] != 0)]\n",
    "baseline_1024 = reg_models_df.loc[(reg_models_df[\"Unnamed: 0\"] == 9) & (reg_models_df[\"rank\"] != 0)]\n",
    "dropout_1024 = reg_models_df.loc[(reg_models_df[\"Unnamed: 0\"] == 10) & (reg_models_df[\"rank\"] != 0)]\n",
    "l2_1024 = reg_models_df.loc[(reg_models_df[\"Unnamed: 0\"] == 12) & (reg_models_df[\"rank\"] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(baseline_256[\"rank\"], baseline_256[\"val_acc\"], color='blue', s=50, label=\"No Regularization\")\n",
    "plt.scatter(l2_256[\"rank\"], l2_256[\"val_acc\"], color=\"red\", s=50, label=\"L2, alpha=0.01\")\n",
    "plt.title(f\"L2's Effect on Truncated Accuracy, nunits=256\")\n",
    "plt.xlabel('Rank')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"./figures/L2_256.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(baseline_1024[\"rank\"], baseline_1024[\"val_acc\"], color='blue', s=50, label=\"No Regularization\")\n",
    "plt.scatter(dropout_1024[\"rank\"], dropout_1024[\"val_acc\"], color=\"red\", s=50, label=\"Dropout, p=0.25\")\n",
    "plt.title(f\"Dropout's Effect on Truncated Accuracy, nunits=1024\")\n",
    "plt.xlabel('Rank')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"./figures/Dropout_1024.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(baseline_1024[\"rank\"], baseline_1024[\"val_acc\"], color='blue', s=50, label=\"No Regularization\")\n",
    "plt.scatter(l2_1024[\"rank\"], l2_1024[\"val_acc\"], color=\"red\", s=50, label=\"Dropout, p=0.25\")\n",
    "plt.title(f\"L2's Effect on Truncated Accuracy, nunits=1024\")\n",
    "plt.xlabel('Rank')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"./figures/L2_1024.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
